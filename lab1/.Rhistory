library(gRain)
source ("import_data.R")
ret <- load.data()
df <- ret$df
header <- ret$header
sapply(df,class)
View(df)
bn1 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
bn2 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
graphviz.plot(bn1)
all.equal(bn1,bn2) # Should be false
############# TASK TWO #############
im_sa_si <- c(1:1)
no_of_arcs <- integer(length=0)
score <- integer(length=0)
opt_sample_size <- numeric(length=0)
for (i in im_sa_si){
bnBD <- hc(df, start = NULL, score = "bde", iss=i,
restart = 3, perturb = 3, max.iter = Inf,
maxp = Inf, optimized = TRUE)
no_of_arcs <- c(no_of_arcs, nrow(bnBD$arcs))
score <- c(score, score(bnBD,df, type = "bde", iss=i))
if (i==1 | i ==2000){
opt_sample_size <- c(opt_sample_size, alpha.star(bnBD, df))
}
}
graphviz.plot(bnBD)
plot(im_sa_si,no_of_arcs, xlab="Imaginary sample size", ylab="Number of arcs")
abline(v = opt_sample_size, untf = FALSE, col="green")
plot(im_sa_si,score, type="l", xlab="Imaginary sample size", ylab="Score")
abline(v = opt_sample_size, untf = FALSE, col="green")
############# TASK THREE #############
finalBN <- hc(df, start = NULL, score = "bde", iss=80,
restart = 0, perturb = 1, max.iter = Inf,
maxp = Inf, optimized = TRUE)
nrow(finalBN$arcs) #8 arcs should be fine
graphviz.plot(finalBN)
copy <- finalBN
### Approximate ###
dfOwn <- df[c(df$Housing=="own"),] # Set observation to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2]
### Exact ###
jTree <- compile(as.grain(fittedMLE))
setFinding(jTree, nodes = "Housing", states = "own")
exact <- querygrain(jTree)
tableOwnFittedMLE = tableOwnManualMLE
dfOwn <- df[c(df$Housing=="own"),] # Set observation to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2]
tableOwnFittedMLE == tableOwnManualMLE
?cpdist
cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))
table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own")))
table(cpdist(fittedMLE, "Good/BadCredit")
)
table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own")))
prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))),)
?compile
jTree <- compile(as.grain(fittedMLE),)
setFinding(jTree, nodes = "Housing", states = "own")
?querygrain
exact <- querygrain(jTree)
exact
jTree <- compile(as.grain(fittedMLE))
exact <- querygrain(jTree, setFinding(jTree, nodes = "Housing", states = "own"))
exact
exact <- querygrain(jTree, "Good/BadCredit")
exact
?prop.table
prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))),3)
prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))),2)
prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
jTree
jTree$isCompiled
jTree$rip$cliques
compileCPT(as.grain(fittedMLE))
jTree <- compile(as.grain(fittedMLE))
jTree
cpt <- compileCPT(as.grain(fittedMLE))
cpt
?compileCPT()
exact <- querygrain(jTree, "Good/BadCredit")
exact
setFinding(jTree, nodes = "Housing", states = "own")
exact <- querygrain(jTree, "Good/BadCredit")
exact
approx0 <- prop.table(table(cpdist(fittedMLE)))
approx0 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit")))
?cpdist
approx0 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit")))
approx0 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", c(Housing == "own",Housing== "rent"))))
exact0 <- querygrain(jTree, "Good/BadCredit")
exact0
############# TASK ONE #############
library(bnlearn)
library(gRain)
source ("import_data.R")
ret <- load.data()
df <- ret$df
header <- ret$header
sapply(df,class)
View(df)
bn1 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
bn2 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
graphviz.plot(bn1)
all.equal(bn1,bn2) # Should be false
############# TASK TWO #############
im_sa_si <- c(1:1)
no_of_arcs <- integer(length=0)
score <- integer(length=0)
opt_sample_size <- numeric(length=0)
for (i in im_sa_si){
bnBD <- hc(df, start = NULL, score = "bde", iss=i,
restart = 3, perturb = 3, max.iter = Inf,
maxp = Inf, optimized = TRUE)
no_of_arcs <- c(no_of_arcs, nrow(bnBD$arcs))
score <- c(score, score(bnBD,df, type = "bde", iss=i))
if (i==1 | i ==2000){
opt_sample_size <- c(opt_sample_size, alpha.star(bnBD, df))
}
}
graphviz.plot(bnBD)
plot(im_sa_si,no_of_arcs, xlab="Imaginary sample size", ylab="Number of arcs")
abline(v = opt_sample_size, untf = FALSE, col="green")
plot(im_sa_si,score, type="l", xlab="Imaginary sample size", ylab="Score")
abline(v = opt_sample_size, untf = FALSE, col="green")
############# TASK THREE #############
finalBN <- hc(df, start = NULL, score = "bde", iss=80,
restart = 0, perturb = 1, max.iter = Inf,
maxp = Inf, optimized = TRUE)
nrow(finalBN$arcs) #8 arcs should be fine
graphviz.plot(finalBN)
### Fit data into BN ###
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
### Compute approximate inference, example ###
dfOwn <- df[c(df$Housing=="own"),] # Set conditional to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2] # Extract probabilities Good/BadCredit given Housing="own"
tableOwnFittedMLE == tableOwnManualMLE # True for all entries
### Compute exact inference ###
jTree <- compile(as.grain(fittedMLE))
### Compare given no observed nodes ###
exact0 <- querygrain(jTree, "Good/BadCredit")
#approx0 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
### Compare given one observed node ###
setFinding(jTree, nodes = "Housing", states = "own")
exact1 <- querygrain(jTree, "Good/BadCredit")
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
exact0
exact1
setFinding(jTree, nodes = "Housing", states = c("own","rent"))
setFinding(jTree, nodes = "Housing", states = "own","rent"))
setFinding(jTree, nodes = "Housing", states = "own","rent")
setFinding(jTree, nodes = "Housing", states = list("own","rent")
)
setFinding(jTree, nodes = "Housing", states = list("own","rent"))
setFinding(jTree, nodes = "Housing", states = "own")
bn1 <- setFinding(jTree, nodes = "Housing", states = "own")
exact1 <- querygrain(bn1, "Good/BadCredit")
exact1
exact0
fittedMLE
fittedMLE$`Good/BadCredit`
fittedMLE$`Good/BadCredit`[,,2]
fittedMLE$`Good/BadCredit`$prob[,,2]
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own")))))
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))),1)
approx1
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))),2)
prop.table
prop.table
?prop.table
?table
approx3 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", c(MaritalAndSex=="A93", Housing == "own", Purpose=="A40"))))
approx3 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (MaritalAndSex=="A93" & Housing == "own" & Purpose=="A40"))))
approx3
exact3 <- querygrain(jTree3, "Good/BadCredit")
jTree3 <- setFinding(jTree, nodes=c("MaritalAndSex","Housing", "Purpose"), states=c("A93", "own", "A40")) #Single male, new car
exact3 <- querygrain(jTree3, "Good/BadCredit")
exact3
difference = exact3 - approx3
difference = exact3$`Good/BadCredit` - approx3
difference
difference1 <- (exact1$`Good/BadCredit`-approx1)$good
difference1 <- (exact1$`Good/BadCredit`-approx1)
difference[1]
difference3[1]
difference3 = exact3$`Good/BadCredit` - approx3
difference3[1]
############# TASK ONE #############
library(bnlearn)
library(gRain)
source ("import_data.R")
ret <- load.data()
df <- ret$df
header <- ret$header
sapply(df,class)
View(df)
bn1 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
bn2 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
graphviz.plot(bn1)
all.equal(bn1,bn2) # Should be false
############# TASK TWO #############
im_sa_si <- c(1:1)
no_of_arcs <- integer(length=0)
score <- integer(length=0)
opt_sample_size <- numeric(length=0)
for (i in im_sa_si){
bnBD <- hc(df, start = NULL, score = "bde", iss=i,
restart = 3, perturb = 3, max.iter = Inf,
maxp = Inf, optimized = TRUE)
no_of_arcs <- c(no_of_arcs, nrow(bnBD$arcs))
score <- c(score, score(bnBD,df, type = "bde", iss=i))
if (i==1 | i ==2000){
opt_sample_size <- c(opt_sample_size, alpha.star(bnBD, df))
}
}
graphviz.plot(bnBD)
plot(im_sa_si,no_of_arcs, xlab="Imaginary sample size", ylab="Number of arcs")
abline(v = opt_sample_size, untf = FALSE, col="green")
plot(im_sa_si,score, type="l", xlab="Imaginary sample size", ylab="Score")
abline(v = opt_sample_size, untf = FALSE, col="green")
############# TASK THREE #############
finalBN <- hc(df, start = NULL, score = "bde", iss=80,
restart = 0, perturb = 1, max.iter = Inf,
maxp = Inf, optimized = TRUE)
nrow(finalBN$arcs) #8 arcs should be fine
graphviz.plot(finalBN)
### Fit data into BN ###
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
### Compute approximate inference, example ###
dfOwn <- df[c(df$Housing=="own"),] # Set conditional to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2] # Extract probabilities Good/BadCredit given Housing="own"
tableOwnFittedMLE == tableOwnManualMLE # True for all entries
### Compute exact inference ###
jTree <- compile(as.grain(fittedMLE))
### Compare given no observed nodes ###
exact0 <- querygrain(jTree, "Good/BadCredit")
#approx0 <- prop.table(table(cpdist(fittedMLE)) # cpdist requires evidence ...
### Compare given one observed node ###
jTree1 <- setFinding(jTree, nodes = "Housing", states = "own")
exact1 <- querygrain(jTree1, "Good/BadCredit")
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
difference1 <- (exact1$`Good/BadCredit`-approx1)
difference[1]
### Compare given three observed nodes ###
jTree3 <- setFinding(jTree, nodes=c("MaritalAndSex","Housing", "Purpose"), states=c("A93", "own", "A40")) #Single male, new car
exact3 <- querygrain(jTree3, "Good/BadCredit")
approx3 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (MaritalAndSex=="A93" & Housing == "own" & Purpose=="A40"))))
difference3 = exact3$`Good/BadCredit` - approx3
difference3[1]
############# TASK ONE #############
library(bnlearn)
library(gRain)
source ("import_data.R")
ret <- load.data()
df <- ret$df
header <- ret$header
sapply(df,class)
View(df)
bn1 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
bn2 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
graphviz.plot(bn1)
all.equal(bn1,bn2) # Should be false
############# TASK TWO #############
im_sa_si <- c(1:1)
no_of_arcs <- integer(length=0)
score <- integer(length=0)
opt_sample_size <- numeric(length=0)
for (i in im_sa_si){
bnBD <- hc(df, start = NULL, score = "bde", iss=i,
restart = 3, perturb = 3, max.iter = Inf,
maxp = Inf, optimized = TRUE)
no_of_arcs <- c(no_of_arcs, nrow(bnBD$arcs))
score <- c(score, score(bnBD,df, type = "bde", iss=i))
if (i==1 | i ==2000){
opt_sample_size <- c(opt_sample_size, alpha.star(bnBD, df))
}
}
graphviz.plot(bnBD)
plot(im_sa_si,no_of_arcs, xlab="Imaginary sample size", ylab="Number of arcs")
abline(v = opt_sample_size, untf = FALSE, col="green")
plot(im_sa_si,score, type="l", xlab="Imaginary sample size", ylab="Score")
abline(v = opt_sample_size, untf = FALSE, col="green")
############# TASK THREE #############
finalBN <- hc(df, start = NULL, score = "bde", iss=80,
restart = 0, perturb = 1, max.iter = Inf,
maxp = Inf, optimized = TRUE)
nrow(finalBN$arcs) #8 arcs should be fine
graphviz.plot(finalBN)
### Fit data into BN ###
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
### Compute approximate inference, example ###
dfOwn <- df[c(df$Housing=="own"),] # Set conditional to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2] # Extract probabilities Good/BadCredit given Housing="own"
tableOwnFittedMLE == tableOwnManualMLE # True for all entries
### Compute exact inference ###
jTree <- compile(as.grain(fittedMLE))
### Compare given no observed nodes ###
exact0 <- querygrain(jTree, "Good/BadCredit")
#approx0 <- prop.table(table(cpdist(fittedMLE)) # cpdist requires evidence ...
### Compare given one observed node ###
jTree1 <- setFinding(jTree, nodes = "Housing", states = "own")
exact1 <- querygrain(jTree1, "Good/BadCredit")
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
difference1 <- (exact1$`Good/BadCredit`-approx1)
approx1
exact1
difference1
### Compare given three observed nodes ###
jTree3 <- setFinding(jTree, nodes=c("MaritalAndSex","Housing", "Purpose"), states=c("A93", "own", "A40")) #Single male, new car
exact3 <- querygrain(jTree3, "Good/BadCredit")
approx3 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (MaritalAndSex=="A93" & Housing == "own" & Purpose=="A40"))))
difference3 = exact3$`Good/BadCredit` - approx3
approx3
exact3
difference3
??random.graph
random.graph(LETTER(A:E))
random.graph(LETTERS(A:E))
random.graph(c(A:E))
?letters
random.graph(LETTERS(5))
letters(a:e)
LETTERS(A:E)
random.graph(LETTERS(1:5))
LETTERS(1:5)
LETTERS[1:5]
random.graph(LETTERS[1:5])
?cpdag
cpdag(DAG)
DAG <- random.graph(LETTERS[1:5])
cpdag(DAG)
DAG <- random.graph(LETTERS[1:5])
DAG
DAG2 <- cpdag(DAG)
DAG2
?lapply
?cpdag
?random.graph
DAG <- random.graph(LETTERS[1:5], num = 29281)
dag
DAG
29281/3
29281/4
29281/5
29281/6
29281/7
rDAG <- random.graph(LETTERS[1:5], num = 4183) # 29281 / 7
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
rDAG
lapply(rDAG, cpdag())
lapply(rDAG, function(x) cpdag(x))
cpdag(rDAG)
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
cpdag(rDAG)
?unique
?length
uqrcpdag <- unique(rcpdag)
rDAG <- random.graph(LETTERS[1:5], num = 4183) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
uqrcpdag <- unique(rcpdag)
unrcpdag
uqrcpdag
length(uqrcpdag)
1006/4183
rDAG <- random.graph(LETTERS[1:5], num = 29281) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
uqrcpdag <- unique(rcpdag)
length(uqrcpdag)
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
uqrcpdag <- unique(rcpdag)
length(uqrcpdag)
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
uqrcpdag <- unique(rcpdag)
length(uqrcpdag)
rDAG
rDAG[[2]]
rDAG[[]]
rDAG <- random.graph(LETTERS[1:5], num = 2)$arcs # 4183 = 29281 / 7
rDAG
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
rDAG
rDAG <- random.graph(LETTERS[1:5], num = 2) # 4183 = 29281 / 7
rDAG
rDAG[[2]]$learning
rDAG[[2]]$nodes
rDAG[[2]]$arcs
rDAG <- random.graph(LETTERS[1:5], num = 4183) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
for (i in 1:4183){
orderedArcs <- c(orderedArcs, rcpdag[[i]]$arcs)
}
uqrcpdag <- unique(orderedArcs)
length(uqrcpdag)
orderedArcs <- rcpdag[[1]]$arcs
############# TASK ONE #############
library(bnlearn)
library(gRain)
source ("import_data.R")
ret <- load.data()
df <- ret$df
header <- ret$header
sapply(df,class)
View(df)
bn1 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
bn2 <- hc(df, start = NULL, whitelist = NULL, blacklist = NULL,
score = NULL, debug = FALSE, restart = 0, perturb = 1,
max.iter = Inf, maxp = Inf, optimized = TRUE)
graphviz.plot(bn1)
all.equal(bn1,bn2) # Should be false
############# TASK TWO #############
im_sa_si <- c(1:1)
no_of_arcs <- integer(length=0)
score <- integer(length=0)
opt_sample_size <- numeric(length=0)
for (i in im_sa_si){
bnBD <- hc(df, start = NULL, score = "bde", iss=i,
restart = 3, perturb = 3, max.iter = Inf,
maxp = Inf, optimized = TRUE)
no_of_arcs <- c(no_of_arcs, nrow(bnBD$arcs))
score <- c(score, score(bnBD,df, type = "bde", iss=i))
if (i==1 | i ==2000){
opt_sample_size <- c(opt_sample_size, alpha.star(bnBD, df))
}
}
graphviz.plot(bnBD)
plot(im_sa_si,no_of_arcs, xlab="Imaginary sample size", ylab="Number of arcs")
abline(v = opt_sample_size, untf = FALSE, col="green")
plot(im_sa_si,score, type="l", xlab="Imaginary sample size", ylab="Score")
abline(v = opt_sample_size, untf = FALSE, col="green")
############# TASK THREE #############
finalBN <- hc(df, start = NULL, score = "bde", iss=80,
restart = 0, perturb = 1, max.iter = Inf,
maxp = Inf, optimized = TRUE)
nrow(finalBN$arcs) #8 arcs should be fine
graphviz.plot(finalBN)
### Fit data into BN ###
fittedMLE <- bn.fit(finalBN, df, method="mle") #done with MLE
### Compute approximate inference, example ###
dfOwn <- df[c(df$Housing=="own"),] # Set conditional to "own"
tableOwnManualMLE <- prop.table(table(dfOwn[,c("Good/BadCredit","CreditHistory")]),2) # Maximum likelihood method
tableOwnFittedMLE <- fittedMLE$`Good/BadCredit`$prob[,,2] # Extract probabilities Good/BadCredit given Housing="own"
tableOwnFittedMLE == tableOwnManualMLE # True for all entries
### Compute exact inference ###
jTree <- compile(as.grain(fittedMLE))
### Compare given no observed nodes ###
exact0 <- querygrain(jTree, "Good/BadCredit")
#approx0 <- prop.table(table(cpdist(fittedMLE)) # cpdist requires evidence!
### Compare given one observed node ###
jTree1 <- setFinding(jTree, nodes = "Housing", states = "own")
exact1 <- querygrain(jTree1, "Good/BadCredit")
approx1 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (Housing == "own"))))
difference1 <- (exact1$`Good/BadCredit`-approx1)
approx1
exact1$`Good/BadCredit`
difference1
### Compare given three observed nodes ###
jTree3 <- setFinding(jTree, nodes=c("MaritalAndSex","Housing", "Purpose"), states=c("A93", "own", "A40")) #Single male, new car
exact3 <- querygrain(jTree3, "Good/BadCredit")
approx3 <- prop.table(table(cpdist(fittedMLE, "Good/BadCredit", (MaritalAndSex=="A93" & Housing == "own" & Purpose=="A40"))))
difference3 = exact3$`Good/BadCredit` - approx3
approx3
exact3$`Good/BadCredit`
difference3
############# TASK FOUR #############
rDAG <- random.graph(LETTERS[1:5], num = 4183) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
orderedArcs <- rcpdag[[1]]$arcs
for (i in 2:4183){
orderedArcs <- c(orderedArcs, rcpdag[[i]]$arcs)
}
uqrcpdag <- unique(orderedArcs)
length(uqrcpdag)
DAG2
?lapply
5/4183
rDAG <- random.graph(LETTERS[1:5], num = 29281) # 4183 = 29281 / 7
rcpdag <- lapply(rDAG, function(x) cpdag(x))
orderedArcs <- rcpdag[[1]]$arcs
for (i in 2:29281){
orderedArcs <- c(orderedArcs, rcpdag[[i]]$arcs)
}
uqrcpdag <- unique(orderedArcs)
fractionSample <- length(uqrcpdag)/29281
fractionSample
fractionSample*100
